# 2. 메모리

## 📌 2.1 메모리 계층

메모리 계층은 레지스터, 캐시, 메모리, 저장장치로 구성되어 있다.

- 레지스터: CPU 안에 있는 작은 메모리, 휘발성, 속도 가장 빠름, 기억 용량이 가장 적음
- 캐시: L1, L2 캐시를 지칭함. 휘발성, 속도 빠름, 기억 용량 적음. L3 캐시도 있음
- 주기억장치: RAM. 휘발성, 속도 보통, 기억 용량 보통
- 보조기억장치: HDD, SSD를 일컬으며 비휘발성, 속도 낮음, 기억 용량 많음

램은 하드디스크로부터 일정량의 데이터를 복사해서 임시 저장하고 이를 필요 시마다 CPU에 빠르게 전달하는 역할을 한다. 계층 위로 올라갈수록 가격은 비싸지는데 용량은 작아지고 속도는 빨라지는 특징이 있다.

⇒ 이러한 계층이 있는 이유는 `경제성`과 `캐시` 때문

<br>


### 🔹 캐시 (Cache)

: 데이터를 미리 복사해 놓는 임시 저장소이자 빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상을 줄이기 위한 메모리

⇒ 데이터 접근 시간이 오래 걸리는 경우 해결, 무언가를 다시 계산하는 시간 절약 가능

→ 속도 차이를 해결하기 위해 계층과 계층 사이에 있는 계층을 `캐싱 계층` 이라고 함.

ex) 캐시 메모리와 보조기억장치 사이에 있는 주기억장치를 보조기억장치의 캐싱 계층이라고 할 수 있음.

`지역성의 원리`

- 시간 지역성(temporal locality): 최근 사용한 데이터에 다시 접근하려는 특성
- 공간 지역성(spatial locality): 최근 접근한 데이터를 이루고 있는 공간이나 그 가까운 공간에 접근하려는 특성

<br>

### 🔹 캐시히트와 캐시미스

- 캐시히트(cache hit): 캐시에서 원하는 데이터를 찾은 것
    - 해당 데이터를 제어장치를 거쳐 가져오게 된다.
    - 위치도 가깝고 CPU 내부 버스를 기반으로 작동하기 때문에 빠름
- 캐시미스(cahe miss): 해당 데이터가 캐시에 없다면 주메모리로 가서 데이터를 찾아오는 것
    - 메모리에서 가져오게 되는데, 이는 시스템 버스를 기반으로 작동하기 때문에 느림

<br>

### 🔹 캐시매핑

: 캐시가 히트되기 위해 매핑하는 방법

- CPU의 레지스터와 주 메모리(RAM) 간에 데이터를 주고받을 때를 기반으로 설명한다.
- 레지스터는 주 메모리에 비하면 굉장히 작고 주 메모리는 굉장히 크기 때문에 작은 레지스터가 캐시 계층으로써 역할을 잘 해주려면 이 매핑을 어떻게 하느냐가 중요함.
- 분류
    - 직접 매핑(directed mapping)
    - 연관 매핑(associative mapping)
    - 집합 연관 매핑(set associative mapping)

<br>

### 🔹 웹 브라우저의 캐시

- **쿠키**: 만료기한이 있는 키-값 저장소
    - `same site` 옵션을 `strict`로 설정하지 않았을 경우 다른 도메인에서 요청했을 때 자동 전송됨
    - 4KB까지 데이터 저장 가능, 만료 기한 설정 가능
    - 쿠키 설정 시 `document.cookie`로 쿠키를 볼 수 없게 `httponly`옵션을 거는 것이 중요
    - 클라이언트 또는 서버에서 만료기한 등을 정할 수 있는데 보통 서버에서 정함.
- **로컬 스토리지**: 만료기한이 없는 키-값 저장소
    - 10MB까지 저장 가능
    - 웹 브라우저를 닫아도 유지됨
    - 도메인 단위로 저장, 생성됨
    - HTML5를 지원하지 않는 웹 브라우저에서는 사용 불가
    - 클라이언트에서만 수정 가능
- **세션 스토리지**: 만료기한이 없는 키-값 저장소
    - 탭 단위로 세션 스토리지 생성, 탭 닫을 때 해당 데이터가 삭제됨
    - 5MB까지 저장 가능
    - HTML5를 지원하지 않는 웹 브라우저에서는 사용 불가
    - 클라이언트에서만 수정 가능
<br>

### 🔹 데이터베이스의 캐싱 계층

데이터베이스 시스템을 구축할 때도 메인 데이터베이스 위에 `레디스(redis)` 데이터베이스 계층을 ‘캐싱 계층’으로 둬서 성능을 향상시킨다고 한다.

![image](https://github.com/Algosippda-CS/Yeonsu-CS/assets/82032452/8debd2cb-7462-4a4f-b694-dfacda084938)


1. 응용 프로그램은 캐시를 질의하고 캐시에 저장된 데이터(캐시 적중)를 사용한다.
2. 데이터가 캐시에 없는 경우(캐시 실패) 기본 스토리지 위치에서 데이터를 검색한다. 이 경우 MySQL 데이터베이스이다.
3. 기본 저장 영역 위치에서 검색된 데이터는 나중에 사용할 수 있도록 캐시에 기록된다.

<br>
<br>

## 📌 2.2 메모리 관리

운영체제의 대표적인 할 일 중 하나가 메모리 관리다.

컴퓨터 내의 한정된 메모리를 극한으로 활용해야 하는 것!

<br>

### 🔹 가상 메모리 (Virtual memory)

: 메모리 관리 기법의 하나로 컴퓨터가 실제로 이용 가능한 메모리 자원을 추상화하여 이를 사용하는 사용자들에게 매우 큰 메모리로 보이게 만드는 것

- 가상 주소(logical address): 가상적으로 주어진 주소
    - 메모리관리장치(MMU)에 의해 실제 주소로 변환됨
- 실제 주소(physical address): 실제 메모리상에 있는 주소

가상 메모리는 가상 주소와 실제 주소가 매핑되어 있고 프로세스의 주소 정보가 들어 있는 ‘페이지 테이블’로 관리된다. 이때 속도 향상을 위해 `TLB`를 쓴다.

> **TLB**
> 
> - 메모리와 CPU 사이에 있는 주소 변환을 위한 캐시
> - 페이지 테이블에 있는 리스트를 보관하며 CPU가 페이지 테이블까지 가지 않도록 해 속도를 향상시킬 수 있는 캐시 계층이다.

<br>

### 🔹 스와핑 (Swapping)

가상 메모리에는 존재하지만 실제 메모리인 RAM에는 현재 없는 데이터나 코드에 접근할 경우 페이지 폴트 발생

→ 이때 메모리에서 당장 사용하지 않는 영역을 하드디스크로 옮기고 하드디스크의 일부분을 마치 메모리처럼 불러와 쓰는 것을 `스와핑(swapping)`이라고 한다.

⇒ 이를 통해 마치 페이지 폴트가 일어나지 않은 것처럼 만든다.

<br>

### 🔹 페이지 폴트 (Page fault)

: 프로세스의 주소 공간에는 존재하지만 지금 이 컴퓨터의 RAM에는 없는 데이터에 접근했을 경우 발생

<페이지 폴트와 그로 인한 스와핑 과정>

1. CPU는 물리 메모리를 확인하여 해당 페이지가 없으면 트랩을 발생해서 운영체제에 알린다.
2. 운영체제는 CPU의 동작을 잠시 멈춘다.
3. 운영체제는 페이지 테이블을 확인하여 가상 메모리에 페이지가 존재하는지 확인하고, 없으면 프로세스를 중단하고 현재 물리 메모리에 비어 있는 프레임이 있는지 찾는다. 물리 메모리에도 없다면 스와핑이 발동된다.
4. 비어 있는 프레임에 해당 페이지를 로드하고, 페이지 테이블을 최신화한다.
5. 중단되었던 CPU를 다시 시작한다.

> **페이지(page)**
> 
> 
> : 가상 메모리를 사용하는 최소 크기 단위
> 
> **프레임(frame)**
> 
> : 실제 메모리를 사용하는 최소 크기 단위
> 

<br>

### 🔹 스레싱 (Thrashing)

: 메모리의 페이지 폴트율이 높은 것을 의미

⇒ 컴퓨터의 심각한 성능 저하 초래

- 스레싱은 메모리에 너무 많은 프로세스가 동시에 올라가게 되면 스와핑이 많이 일어나서 발생하는 것이다.
- 페이지 폴트 발생 → CPU 이용률 낮아짐 → 운영체제는 “CPU가 한가한가?”라고 생각하여 더 많은 프로세스를 메모리에 올림 → 악순환 반복 ⇒ 스레싱 발생
- 해결방안
    - 메모리를 늘린다.
    - HDD를 사용한다면 HDD를 SSD로 바꾼다.
    - 운영체제에서 해결: 작업 세트와 PFF
        - 작업세트: 지역성(locality)를 통해 결정된 페이지 집합을 만들어서 미리 메모리에 로드 ⇒ 탐색 비용, 스와핑 절감
        - PFF(Page Fault Frequency): 상한선과 하한선을 만들어서 페이지 폴트 빈도를 조절하는 방법. 상한선에 도달하면 프레임을 늘리고, 하한선에 도달하면 줄이는 것

<br>

### 🔹 메모리 할당

메모리에 프로그램을 할당할 때는 시작 메모리 위치, 메모리의 할당 크기를 기반으로 할당하는데, 연속 할당과 불연속 할당으로 나뉜다.

- **연속할당**: 메모리에 ‘연속적으로’ 공간을 할당하는 것
    - **고정 분할 방식(fixed partition allocation)**: 메모리를 미리 나누어 관리하는 방식. 메모리가 미리 나뉘어 있기 때문에 융통성이 없고 내부 단편화가 발생한다.
    - **가변 분할 방식(variable partition allocation)**: 매 시점 프로그램의 크기에 맞게 동적으로 메모리를 나눠 사용한다. 내부 단편화 발생X, 외부 단편화 발생 가능. 최초적합(first fit), 최적적합(best fit), 최악적합(worst fit)이 있다.
    <br>
    
    > **내부 단편화(internal fragmentation)**
    > 
    > 
    > : 메모리를 나눈 크기보다 프로그램이 작아서 들어가지 못하는 공간이 많이 발생하는 현상
    > 
    > **외부 단편화(external framentation)**
    > 
    > : 메모리를 나눈 크기보다 프로그램이 커서 들어가지 못하는 공간이 많이 발생하는 현상
    > 
    > **홀(hole)**
    > 
    > : 할당할 수 있는 비어 있는 메모리 공간
    > 
- **불연속 할당**: 메모리를 연속적으로 할당하지 않는 할당 방법
    - **페이징(paging)**: 동일한 크기의 페이지 단위로 나누어 메모리의 서로 다른 위치에 프로세스 할당함.
        - 장점) 홀의 크기가 균일하지 않은 문제가 없어짐
        - 단점) 주소 변환이 복잡해짐
    - **세그멘테이션(segmentation)**: 세그먼트(segment)로 나누는 방식.
        - 장점) 공유와 보안 측면에서 good
        - 단점) 홀 크기가 균일하지 않다.
    - **페이지드 세그멘테이션(page segmentation)**: 프로그램을 의미 단위인 세그먼트로 나눠 공유나 보안 측면에 강점을 두고 임의의 길이가 아닌 동일한 크기의 페이지 단위로 나누는 것

<br>

### 🔹 페이지 교체 알고리즘

메모리는 한정되어 있기 때문에 스와핑이 많이 일어난다. 스와핑이 많이 일어나지 않도록 설계되어야 하며, 이는 페이지 교체 알고리즘을 기반으로 스와핑이 일어난다.

- **오프라인 알고리즘(offline algorithm)**: 먼 미래에 참조되는 페이지와 현재 할당하는 페이지를 바꾸는 알고리즘. 가장 좋은 방법. 하지만 미래에 사용되는 프로세스를 알 수 없다. 사용할 수는 없지만 다른 알고리즘과의 성능 비교에 대한 상한기준(upper_bound) 제공함.
- **FIFO(First In First Out)**: 가장 먼저 온 페이지를 교체 영역에 가장 먼저 놓는 방법
- **LRU(Least Recentle Used)**: 참조가 가장 오래된 페이지를 바꿈. ‘오래된’ 것을 파악하기 위해 각 페이지마다 계수기, 스택을 두어야 하는 문제점이 있음.
- **NUR(Not Used Recently)**: LRU에서 발전한 방법. 일명 clock 알고리즘. 시계 방향으로 돌면서 0을 찾고 0을 찾은 순간 해당 프로세스를 교체하고, 해당 부분을 1로 바꾸는 알고리즘
- **LFU(Least Frequently Used)**: 가장 참조 횟수가 적은 페이지를 교체함. 즉, 많이 사용되지 않은 것을 교체.
